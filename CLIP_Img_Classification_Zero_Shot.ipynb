{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDqfpb3Y79QX7f7VwbqUbn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amir-asari/CLIP-Basic/blob/main/CLIP_Img_Classification_Zero_Shot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import necessary libraries"
      ],
      "metadata": {
        "id": "bvhMyf7MnZnD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFAyr75ynIy4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision.datasets import CIFAR10\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm # For a nice progress bar\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ==============================================================================\n",
        "### STEP 1: Load Model, Processor, and Dataset\n",
        "### ==============================================================================\n",
        "This step loads the pre-trained model, its processor, and the dataset.\n",
        "For a proper zero-shot evaluation, we use the TEST set."
      ],
      "metadata": {
        "id": "RnEHzg-qni-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if a GPU is available and set the device accordingly\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# --- Load Model and Processor ---\n",
        "print(\"Loading CLIP model and processor...\")\n",
        "try:\n",
        "    model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
        "    processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "    print(\"CLIP model and processor loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model or processor: {e}\")\n",
        "    model = None # Set to None on failure\n",
        "\n",
        "# --- Load Dataset ---\n",
        "# We load the CIFAR-10 test set for evaluation.\n",
        "print(\"\\nLoading CIFAR-10 test dataset...\")\n",
        "try:\n",
        "    # Use train=False to get the test set\n",
        "    test_dataset = CIFAR10(root=\"./data\", train=False, download=True)\n",
        "    print(\"CIFAR-10 test dataset loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading CIFAR-10 dataset: {e}\")\n",
        "    test_dataset = None # Set to None on failure"
      ],
      "metadata": {
        "id": "wD7VRltpnsa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ==============================================================================\n",
        "### STEP 2: Define the Zero-Shot Prediction Function\n",
        "### ==============================================================================\n",
        "This function performs the core zero-shot prediction for a single image.\n",
        "It returns the predicted class name without printing or plotting."
      ],
      "metadata": {
        "id": "RYFgO2l6n3MA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_zero_shot(model, processor, image, class_names):\n",
        "    \"\"\"\n",
        "    Performs zero-shot classification for a single image using CLIP.\n",
        "\n",
        "    Args:\n",
        "        model (CLIPModel): The pre-loaded CLIP model.\n",
        "        processor (CLIPProcessor): The pre-loaded CLIP processor.\n",
        "        image (PIL.Image): The image to classify.\n",
        "        class_names (list): A list of target class names.\n",
        "\n",
        "    Returns:\n",
        "        str: The predicted class name.\n",
        "    \"\"\"\n",
        "    if not model or not processor:\n",
        "        return \"N/A\"\n",
        "\n",
        "    # Create the text prompts for zero-shot classification\n",
        "    text_prompts = [f\"a photo of a {class_name}\" for class_name in class_names]\n",
        "    inputs = processor(\n",
        "        text=text_prompts,\n",
        "        images=image,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True\n",
        "    ).to(device)\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits_per_image = outputs.logits_per_image\n",
        "        # Get the index of the highest probability\n",
        "        prediction_index = logits_per_image.argmax(dim=1).item()\n",
        "\n",
        "    return class_names[prediction_index]"
      ],
      "metadata": {
        "id": "WTvqTDRAoKXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ==============================================================================\n",
        "### STEP 3: Run Zero-Shot Evaluation on the Test Set\n",
        "### ==============================================================================\n",
        "We'll now loop through a sample of the test set, get predictions,\n",
        "and calculate the overall zero-shot accuracy."
      ],
      "metadata": {
        "id": "13IQolsDoPKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configuration ---\n",
        "NUM_SAMPLES_TO_EVALUATE = 1000 # Evaluate on 1000 images for a good estimate\n",
        "if test_dataset:\n",
        "    class_names = test_dataset.classes\n",
        "    correct_predictions = 0\n",
        "    true_labels = []\n",
        "    predicted_labels = []\n",
        "\n",
        "    print(f\"\\n--- Starting Zero-Shot Evaluation on {NUM_SAMPLES_TO_EVALUATE} CIFAR-10 Test Images ---\")\n",
        "\n",
        "    # --- Evaluation Loop ---\n",
        "    # Using tqdm for a progress bar\n",
        "    for i in tqdm(range(NUM_SAMPLES_TO_EVALUATE), desc=\"Evaluating\"):\n",
        "        # Get image and true label\n",
        "        image, true_label_id = test_dataset[i]\n",
        "        true_label_name = class_names[true_label_id]\n",
        "        true_labels.append(true_label_name)\n",
        "\n",
        "        # Get the prediction\n",
        "        predicted_label_name = predict_zero_shot(model, processor, image, class_names)\n",
        "        predicted_labels.append(predicted_label_name)\n",
        "\n",
        "        # Check if the prediction was correct\n",
        "        if predicted_label_name == true_label_name:\n",
        "            correct_predictions += 1\n",
        "\n",
        "    # --- Calculate and Display Accuracy ---\n",
        "    if NUM_SAMPLES_TO_EVALUATE > 0:\n",
        "        accuracy = (correct_predictions / NUM_SAMPLES_TO_EVALUATE) * 100\n",
        "        print(\"\\n--- Zero-Shot Evaluation Complete ---\")\n",
        "        print(f\"Evaluated on: {NUM_SAMPLES_TO_EVALUATE} images\")\n",
        "        print(f\"Correct Predictions: {correct_predictions}\")\n",
        "        print(f\"Overall Zero-Shot Accuracy: {accuracy:.2f}%\")\n",
        "    else:\n",
        "        print(\"No samples were evaluated.\")"
      ],
      "metadata": {
        "id": "pxeyT8-boYW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ==============================================================================\n",
        "### STEP 4: Display Detailed Performance Metrics\n",
        "### =============================================================================="
      ],
      "metadata": {
        "id": "sW81Xkx8onAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Classification Report ---\")\n",
        "    # Generate and print the classification report\n",
        "    report = classification_report(true_labels, predicted_labels, labels=class_names)\n",
        "    print(report)\n",
        "\n",
        "    print(\"\\n--- Confusion Matrix ---\")\n",
        "    # Generate the confusion matrix\n",
        "    cm = confusion_matrix(true_labels, predicted_labels, labels=class_names)\n",
        "\n",
        "    # Plot the confusion matrix using seaborn\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title('Confusion Matrix', fontsize=16)\n",
        "    plt.ylabel('True Label', fontsize=12)\n",
        "    plt.xlabel('Predicted Label', fontsize=12)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"Cannot run evaluation because the dataset failed to load.\")"
      ],
      "metadata": {
        "id": "RYVYuBWaot-p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}